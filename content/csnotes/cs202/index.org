#+TITLE: CS202 Notes
#+OPTIONS: tex: t
#+STARTUP: latexpreview
#+AUTHOR: Berkan Şahin
#+DRAFT: true
#+DATE: 2022-03-22T08:50:00+03:00
#+katex: true

* A pretty important note
These notes are pretty disorganized at the moment, I shall (hopefully) extend some sections as I 
go through the document (which can take a few days, since the document is approximately 1.1K lines long, not
counting heaps and AVL trees). I am posting these because they /might/ be useful to someone, but I give
no guarantees on that regard.
** TODO List
*** [ ]  use a font without ligatures for code listings
*** [ ]  replace local slide links with links to the slides on the course webpage
*** [ ]  find a way to typeset the LaTeX expressions

* Study resources
These two sites contain problems that can help with the exams, interviews for jobs/internships and your problem solving skills in general

[[https://hackerrank.com][Hackerrank]]
[[https://leetcode.com][Leetcode]]

* Algorithm Analysis
[[file:../slides/1_analysis.pptx][Slideshow]]
** C++ code examples (iterative)
*** Time complexity : $O(n)$
#+begin_src cpp
for (int i = 0; i <= n; i+=2) {
    k++;
}
#+end_src

*** Time complexity : $O(\log{n})$
#+begin_src cpp
for (int i = 0; i <= n; i+=2) {
    k++;
}
#+end_src

*** Time complexity: $O(m\log{n})$
#+begin_src cpp
for (int i = n; i >= 1; i /= 20) {
    j = m;
    while (j >= 1)
        j -= 20;
}
#+end_src

*** Time complexity : $O(n^2)$
#+begin_src cpp
i = 0;
while (i < n * n * n) {
    i =  i + (2 * n);
}
#+end_src

** Recursive functions
*** Towers of Hanoi
#+begin_src cpp
void hanoi(int n, char source, char dest, char spare) {
    if (n > 0) {
        hanoi(n - 1, source, spare, dest);
        // Move from source to dest
        hanoi(n - 1, spare, dest, source);
    }
}
#+end_src
1. Write a recurrence relation for the ~hanoi~ function
2. Solve the recurrence relation
   - We will use *repeated substitutions*
**** Solution
\begin{align}
T(n) & = 2 * T(n - 1) + \Theta(1) \\
T(0) & = \Theta(1)
\end{align}
- Solve using repeated substitution
\begin{align}
    T(n) & = 2 * [2 * T(n-2) + \Theta(1)] + \Theta(1) \\
         & = 2 * [2 * [2 * T(n-3) + \Theta(1)] + \Theta(1)] + \Theta(1) \\
         & = 2^k * T(n-k) + \Sigma_{i=0}^{k-1}2^i * \Theta(1) \\
         & = 2^n * T(0) + [2^n - 1] * \Theta(1) \\
         & = \Theta(2^n)
\end{align}
*** General sketch (Repeated Substitution)
1. Formulate the recurrence relation
2. Start with general formula, substitute recurrence on RHS repeatedly
   - We conduct an intermediate step general formula
3. Substitute the intermediate step variables properly and reach basis
4. Simplify the result
*** Factorial function
#+begin_src cpp
int factorial(int n) {
    if (n <= 1)
        return 1;

    return n * factorial(n - 1);
}
#+end_src

**** Solution
- Recurrence relation
    \begin{align}
    T(n) & = T(n-1) + \Theta(1) \\
    T(n) & = \Theta(1)
    \end{align}
- Repeated substitution
  \begin{align}
    T(n) & = T(n - 2) + \Theta(1) + \Theta(1) \\
         & = T(n - 3) + \Theta(1) + \Theta(1) + \Theta(1) \\
         & = T(n - k) + k * \Theta(1) \\
         & = T(n - (n - 1)) + (n - 1) * \Theta(1) \\
         & = T(1) + (n - 1) * \Theta(1) \\
         & = \Theta(1) + (n - 1) * \Theta(1) \\
         & = \Theta(n)
  \end{align}
*** Binary search
#+begin_src cpp
int binarySearch(int a[], int key, int low, int high) {
    if (low > high)
        return -1;

    int mid = (low + high) / 2;

    if (a[mid] == key)
        return mid;

    if (a[mid] > key)
        return binarySearch(a, key, low, mid - 1);

    return binarySearch(a, key, mid + 1, high);
}
#+end_src

**** Solution
- Recurrence relation (we consider the worst case)
\begin{align}
T(n) & = T(n/2) + \Theta(1) \text{ (where n = high - low)} \\
T(1) & = \Theta(1)
\end{align}
- Use repeated substitution
\begin{align}
T(n) & = T(n/2^2) + \Theta(1) + \Theta(1) \\
     & = T(n/2^3) + 3 * \Theta(1) \\
     & = T(n/2^k) + k * \Theta(1) \\
     & = T(n/2^{\log_2{n}}) + \log_2{n} * \Theta(1) \\
     & = T(1) + \log_2{n} * \Theta(1) \\
     & = \Theta(1) + \log_2{n} * \Theta(1) \\
     & = (\log_2{n} + 1) \Theta(1) \\
     & = \Theta(\log{n})
\end{align}
* Searching and Sorting
[[file:../slides/2_sorting.pptx][Slideshow]]
** Problem of the day
True or false?
1. $2n^2 + 1 = O(n^2)$ : True
2. $\sqrt{n} = O(\log{n})$ : False
   Because $\sqrt{n}$ grows faster than $\log{n}$
3. $\log{n} = O(\sqrt{n})$ : True
   Because $\sqrt{n}$ grows faster than $\log{n}$
4. $n^2(1+\sqrt{n}) = O(n^2\log{n})$ : False
   $n^2\sqrt{n}$ dominates the left hand side
5. $3n^2 + \sqrt{n} = O(n^2)$ : True
6. $\sqrt{n}\log{n} = O(n)$ : True
   Replace $\log{n}$ w/ $O(\sqrt{n})$
7. $\log{n} = O(n^{-1/2})$ : False
   RHS is decreasing, so cannot be upper bound
** Searching
*** Sequential Search
#+begin_src cpp
int sequentialSearch(const int a[], int item, int n){
    int i;
	for (i = 0; i < n && a[i] != item; i++);
	if (i == n)
		return –1;
	return i;
}
#+end_src
- Unsuccessful search :: $O(n)$
- Successful search
  - Best case :: Item is in the 1st location of the array
    $O(1)$
  - Worst case :: Item is in the last location of the array
    $O(n)$
  - Average case :: The number of key comparisons 1, 2, ..., n
    (assuming uniform distribution)
    \begin{equation*}
    \frac{\sum_{i = 1}^{n} i}{n} = \frac{(n^2+n)/2}{n} => O(n)
    \end{equation*}
*** Binary Search
- We need to have the elements sorted in order to use bin. search
#+begin_src cpp
int binarySearch( int a[], int size, int x) {
   int low =0;
   int high = size –1;
   int mid; 	  // mid will be the index of
   		  	  // target when it’s found.
   while (low <= high) {
 	   mid = (low + high)/2;
	   if (a[mid] < x)
        low = mid + 1;
	   else if (a[mid] > x)
		   high  = mid – 1;
     else
		   return mid;
   }
   return –1;
}
#+end_src
- Runs in $O(\log{n})$ time, since the problem size ~~high - low~~ is halved every iteration
** Sorting
*** Why don't CS profs ever stop talking about sorting?
1. Computers spend more time sorting than anything else, historically 25% on mainframes.

2. Sorting is the best studied problem in computer science, with a variety of different algorithms known.

3. Most of the interesting ideas we will encounter in the course can be taught in the context of sorting, such as divide-and-conquer, randomized algorithms, and lower bounds.
*** What is sorting
- Organize data into ascending/descending order
- Internal sort :: The data is always in the memory
  - *We will only analyze internal sort*
- External sort :: The data doesn't fit in the memory (e.g. a 30GB dataset sorted on a computer w/ 16GB of RAM)
  - Read a chunk from secondary storage, sort, write to disk, repeat until all data is sorted
  - Need to merge the sorted chunks in the disk
- Sorting can make some algos (like finding the intersection of 2 sets) faster (sorting may not be our ultimate goal)

*** Efficiency of sorting
- Using $O(n \log{n})$ algorithms leads to sub-quadratic algos
  #+call: shot()

  #+RESULTS:
  [[file:./pics/220215-0916-30.png]]

*** Applications of Sorting
- Closest pair :: Given n numbers, find the pair which are closest to each other
  - Once the numbers are sorted, do a linear scan ( $O(n)$ ), the closest elements are adjacent elems where the difference between them is minimum
- Element uniqueness :: Given a set of n items, are they all unique or are there any duplicates?
*** Sorting Algorithms
**** Selection Sort $O(n^2)$
- List divided into sorted/unsorted
- find the largest item from unsorted part
- swap w/ the element at the end of unsorted part
- now the sorted part can grow by one
#+call: shot()

#+RESULTS:
[[file:./pics/220215-0939-01.png]]

#+begin_src cpp
typedef type-of-array-item DataType;

void swap(DataType &a, DataType &b) {
    DataType tmp = a;
    a = b;
    b = tmp;
}

int indexOfLargest(DataType arr[], int n) {
    int maxIdx = 0; // Assume 1st elem is largest
    for (int i = 1; i < n; i++) {
        if (arr[i] > arr[maxIdx])
            maxIdx = i;
    }

    return maxIdx;
}

void selectionSort( DataType theArray[], int n) {
  for (int last = n-1; last >= 1; --last) {
    int largest = indexOfLargest(theArray, last+1);
    swap(theArray[largest], theArray[last]);
  }
}
#+end_src

***** Analysis
- ~indexOfLargest~ runs in $O(last + 1)$ time for each iteration
- ~swap~ runs in $O(1)$ time
- Overall time complexity: $\sum_{i = 1}^n i = O(n^2)$
- Total swaps: $n - 1$
- Total moves: $3 * (n - 1)$
- Best case = worst case = avg case = $O(n^2)$
- Selection sort only requires $O(n)$ moves
  - Useful when moves are *much* slower than comparisons
**** Insertion Sort $O(n^2)$
- List divided into sorted/unsorted
- The first element of the unsorted part is inserted in place in the sorted sublist
- At most $n - 1$ passes in a list of $n$ elements
  #+call: shot()

  #+RESULTS:
  [[file:./pics/220215-0955-16.png]]

***** Notes
- Items are sorted in place
- Incremental approach :: Useful for streams

***** C++ code
#+begin_src cpp
void insertionSort(DataType theArray[], int n) {

  for (int unsorted = 1; unsorted < n; ++unsorted) {

    DataType nextItem = theArray[unsorted];
    int loc = unsorted;

    for (  ;(loc > 0) && (theArray[loc-1] > nextItem); --loc)
       theArray[loc] = theArray[loc-1];

    theArray[loc] = nextItem;
  }
}
#+end_src

***** Analysis
****** Best case: $O(n)$
- The array is already sorted in ascending order
- The inner loop is skipped
- The number of move operations :: $2 * (n - 1) \implies O(n)$
- The number of comparisons :: $(n - 1) \implies O(n)$
****** Worst case: $O(n^2)$
- The array is sorted in reverse
- Inner loop is executed j times for $j = 1,2,3,...,n$
- The number of moves :: $2*(n-1) + \sum_{i=1}^{n-1}i = 2*(n-1)+\frac{n*(n-1)}{2} \implies O(n^2)$
****** Average case: $O(n^2)$
- *Needs probabilistic analysis*

**** Bubble Sort $O(n^2)$
- Divide the array into sorted/unsorted parts
- We assume a "bubble" which moves towards the end of the array
- Checks i-1 and ith element for $i = 2,3,4,...,k$, swaps them if ~A[i] < A[i-1]~
- where k denotes the imaginary boundary between the sorted and the unsorted sublists
- At each pass the largest element (in the unsorted portion) is moved to the end of the array, and k is decremented

***** C++ code
#+begin_src cpp
void bubbleSort( DataType theArray[], int n) {
   bool sorted = false;

	for (int pass = 1; (pass < n) && !sorted; ++pass) {
      sorted = true;
      for (int index = 0; index < n-pass; ++index) {
         int nextIndex = index + 1;
         if (theArray[index] > theArray[nextIndex]) {
            swap(theArray[index], theArray[nextIndex]);
            sorted = false; // signal exchange
         }
      }
   }
}
#+end_src

****** Notes
- Since bubble sort makes the array more ordered for each pass, it may reach the sorted state early, therefore it is a good idea to check if the array is sorted (to avoid unnecessary passes)

***** Analysis
****** Worst case: $O(n^2)$
- The array is in reverse order
- Therefore the algorithm always performs a swap and does n passes
- The number of moves :: $\sum_{i=1}^{n-1}3i = 3n(n-1)/2 \implies O(n^2)$
- The number of comparisons :: $\sum_{i=1}^{n-1}i \implies O(n^2)$
****** Best case: $O(n)$
- The array is already sorted
- Therefore the algorithm performs one pass and no swaps
- Number of moves :: $0 \implies O(1)$
- Number of comparisons :: $O(n)$
****** Average case: $O(n^2)$

**** Merge Sort $O(n \log{n})$
- A divide and conquer algorithm

***** Algorithm
1. Divide the array into two halves
2. Sort each half separately
3. Merge the two halves into one sorted array

#+call: shot()

#+RESULTS:
[[file:./pics/220217-1357-13.png]]

***** Pseudocode
#+begin_src python
def merge_sort(Arr, begin, end):
    # the array is sorted (base case)
    if begin == end:
        return
    else:
        # sort halves independently
        mid = (p + r) / 2
        merge_sort(Arr, begin, mid)
        merge_sort(Arr, mid, end)
        # merge the sorted halves
        merge(Arr, begin, mid, end)
#+end_src
***** Merging two sorted sub-arrays
- Keep indices of the two subarrays (i,j)
- Compare A[i] and B[j]
- Move the smaller element to the result array
- increment the index of the arr containing the smaller element
- repeat until reaching the end of one of the arrays
- If one of the arrays has remaining items, move them to the result array
- Complexity :: $\Theta(n)$
#+call: shot()

#+RESULTS:
[[file:./pics/220217-1410-37.png]]
***** C++ code
#+begin_src cpp
void mergesort( DataType theArray[], int first, int last) {

	if (first < last) {

      int mid = (first + last)/2; 	// index of midpoint

      mergesort(theArray, first, mid);

      mergesort(theArray, mid+1, last);

      // merge the two halves
      merge(theArray, first, mid, last);
   }
}  // end mergesort
#+end_src

#+begin_src cpp
void merge(DataType arr[], int first, int mid, int last) {
 	DataType tempArray[MAX_SIZE]; 	// temporary array

	 int first1 = first; 	// beginning of first subarray
   int last1 = mid; 		// end of first subarray
   int first2 = mid + 1;	// beginning of second subarray
   int last2 = last;		// end of second subarray
   int index = first1; // next available location in tempArray

   for ( ; (first1 <= last1) && (first2 <= last2); ++index) {
      if (theArray[first1] < theArray[first2]) {
         tempArray[index] = theArray[first1];
         ++first1;
      }
      else {
          tempArray[index] = theArray[first2];
          ++first2;
      }
   }
    // finish off the first subarray, if necessary
   for (; first1 <= last1; ++first1, ++index)
      tempArray[index] = theArray[first1];

   // finish off the second subarray, if necessary
   for (; first2 <= last2; ++first2, ++index)
      tempArray[index] = theArray[first2];

   // copy the result back into the original array
   for (index = first; index <= last; ++index)
      theArray[index] = tempArray[index];
}
#+end_src
***** Analysis
****** Merge
- Complexity is always $O(n)$
****** Merge sort
******* Recurrence relation
\begin{align}
T(n) & = 2T(n/2) + \Theta(n) \\
T(1) & = \Theta(1)
\end{align}
******* Repeated substitution
\begin{align}
T(n) & = 2T(n/2) + \Theta(n) \\
     & = 2[2T(n/4) + \Theta(n/2)] + \Theta(n) \\
     & = 2^2 T(n/2^2) + 2\Theta(n/2) + \Theta(n)
= 2^2 T(n/2^2) + 2\Theta(n) \\
     & = 2^kT(n/2^k) + k\Theta(n) \\
& \text{(when k = log2(n))} \\
& = n*\Theta(1) + \log_2{n}\Theta(n) \\
& = \Theta(n \log_2{n})
\end{align}
******* Notes
- Merge sort is an extremely efficient algorithm (worst and avg cases are $O(n \log{n})$)
- But it requires an extra array to use during merge
- The extra array is not needed w/ a linked list
  - But with a linked list, dividing the list requires a linear pass (which is $O(n)$)
**** Quick Sort $O(n \log{n})$
- Another divide-and-conquer algorithm
- Difference from merge sort :: Hard work is done before the recursive calls
***** Algorithm
1. Partition the array into two parts
   - Choose an element called the pivot (hoping it's close to the median of the array)
   - Elements with values < pivot go to the 1st part, values >= pivot go to the 2nd part
2. Sort the arrays independently
3. Combine (concatenate) the sorted parts
***** Partitioning the array
#+call: shot()
1. Select a pivot element and place it into the 1st location
2. 3 regions are considered during partitioning
   - $S_1$, where all elements are < pivot
   - $S_2$, where all elements are >= pivot
   - The unknown region, which contains elements not yet compared w/ pivot
   #+call: shot()

   #+RESULTS:
   [[file:./pics/220217-1516-32.png]]

3. Compare elements in unknown w/ the pivot
   - If element belongs in $S_2$, increment firstUnknown
   - If element belongs in $S_1$
     1. swap w/ the first item of $S_2$
     2. increment both lastS1 and firstUnknown (since we know the item we swapped the unknown with is in $S_2$)

4. Determine the index for the pivot and move it
#+RESULTS:
[[file:./pics/220217-1500-57.png]]

5. Call quick sort on $S_1$ and $S_2$
   - Every element in $S_1$ is smaller than any element in $S_2$
   - that is, $a < b \forall (a, b) \in (S_1, S_2)$
***** TODO C++ code
***** Analysis
****** Worst case
- When the 1st element is selected as the pivot and the list is already sorted
- The pivot divides the list into two sublists of size $n-1$ and 0
- The number of key comparisons
  $(n-1)+(n-2)+...+(1) = n^2/2-n/2 \implies O(n^2)$
- The number of swaps
  $(n-1)+(n-2)+...+(1)=n^2/2-n/2 \implies O(n^2)$
****** Average case
- $O(n*\log_2{n})$
****** Best case
- $O(n * \log_2{n})$
**** Notes
  - Quicksort is one of the fastest sorting algorithms *that uses comparisons*
  - Sorting algorithms using comparisons cannot be faster than $O(n * \log{n})$
  - Algorithms like radix sort, counting sort etc. don't use comparisons
  - [[https://www.youtube.com/watch?v=_KhZ7F-jOlI][Why sorting algorithms w/ comparisons can't be faster than O(nlogn) (YouTube Video)]]
* Trees
[[file:../slides/trees.pptx][Slideshow]]
** Definition of a tree
- T is a tree if
  a. It has no nodes (leaf)
  b. It has n>0 nodes which are also trees
** Tree Terminology
(Assuming the tree grows downwards)
- Parent :: The parent of a node n is the node directly above it
- Child :: The child(ren) of a node n is/are the node(s) directly below it
- Root :: The only node in a tree that has no parent
- Leaf :: A node with no children
- Siblings :: Nodes with a common parent
- Ancestor :: Ancestor of a node n is a node on the path between the root and the node n
- Descendant :: A descendant of a node n is any node on the path between n and a leaf node
- Subtree :: A subtree of a node n is a tree that has a child of n as its root
** An example tree
#+call: shot()

#+RESULTS:
[[file:./pics/220222-0901-31.png]]
- Node A has children {B, C, D, E, F, G}
- {B, C, H, I, P, Q, K, L, M, N} are *leaves*
- K, L, M are siblings (since their parent is F)
** Some properties of a tree
- NOTE: We assume that a tree is a directed graph
- A tree with N nodes has N-1 edges
- Path :: A path from node $n_1$ to $n_k$ is a sequence of nodes $n_1, n_2, n_3, ..., n_k$ such that $n_i$ is the parent of $n_{i+1}$ $(1 \le i < k)$
** Level of a node
- The number of nodes on the path from root to a node n
*** Recursive definition
- If node n is the root of the tree T, its level is 1
- If n is not the root of T, its level is 1 + the level of its parent
** Height of a tree
- The number of nodes on the longest path from the root to any leaf nodes
*** Definition 1
- If T is empty, its height is 0
- If T is not empty, its height is equal to the maximum level of its nodes
*** Recursive definition
- If T is empty, its height is 0
- If T is not empty, its height is $1 + max(height(T_1), height(T_2),..., height(T_n))$ where $T_1$ through $T_n$ are the subtrees of the root node

  #+call: shot()

  #+RESULTS:
  [[file:./pics/220222-0915-50.png]]
** Binary tree
- A binary tree is a tree where the nodes have at most two children
- Called left and right children
*** Terminology
- Left Child :: Left child of a node n is the node directly below and to the left of n
- Right Child :: Right child of a node n is the node directly below and to the right of n
- Left Subtree of node n :: A binary tree that has the left child of n as its root
- Right Subtree of node n :: A binary tree that has the right child of n as its root
*** Examples
#+call: shot()

#+RESULTS:
[[file:./pics/220222-0920-24.png]]

#+call: shot()

#+RESULTS:
[[file:./pics/220222-0920-44.png]]
*** Height of a binary tree
- Same as the height of a generic tree
*** Number of possible binary trees with n nodes
- n = 0 :: 1
  - Only the empty tree
- n = 1 :: 1
  - A tree with only the root node
- n = 2 :: 2
  - Root node + left child *OR* Root node + right child
*** The General Rule
- Add the possible subtree configurations together
- That is, for n nodes, construct a binary tree with k nodes as the left subtree and  n - 1 - k nodes as the right subtree
- Repeat for all possible k values to obtain all possible configurations
**** Mathematical expression
- If n is odd ::
  $NumBT(n) = 2 \sum_{i=0}^{(n-1)/2} (NumBT(i)NumBT(n-i-1)) + NumBT((n-1)/2)NumBT((n-1)/2)$
- If n is even ::
  $NumBT(n) = 2 \sum_{i=0}^{(n-1)/2} (NumBT(i)NumBT(n-i-1))$
*** Full Binary Tree
- A full binary tree of height h is a tree where nodes with a level < h all have 2 children
  #+call: shot()

  #+RESULTS:
  [[file:./pics/220222-0944-39.png]]

*** Complete Binary Tree
- A complete binary tree is a tree which is full down to level h - 1 with level h filled from left to right
- A binary tree of height h is complete when
  1. All nodes above the level h - 2 have 2 chlidren
  2. A node at level h - 1 has children only if all nodes to its left have 2 children
  3. A node at level h - 1 can either have 2 children or only a left child
#+call: shot()

#+RESULTS:
[[file:./pics/220222-0944-57.png]]

*** Balanced Binary Tree
- A binary tree where the height of any node's left and right subtrees differ no more than 1

*** Maximum and minimum heights of a binary tree
- The efficiency of most binary tree operations depends on tree height
  - Because most algorithms traverse the tree starting from the root node and continue down one of the subtrees
- The maximum height of a tree with n nodes is n
  - When every node has at most 1 child
- In a minimum height tree, each level must contain as many nodes as possible (except the last level)
*** Some height theorems
- A full binary tree of height h has $2^h-1$ nodes
- The minimum height of a binary tree with n nodes is $\lceil log_2{(n+1)} \rceil$

*** Tree Traversal Types
- Preorder Traversal :: visit the node before its children
- Postorder Traversal :: visit the node after its children
- Inorder Traversal :: visit left child, node, then right child
#+call: shot()

#+RESULTS:
[[file:./pics/220224-1404-11.png]]
*** The BinaryTree ADT

**** Array-based Implementation
- copied verbatim from the textbook
**** TreeNode.h
#+begin_src cpp
const int MAX_NODES = 100; 	// maximum number of nodes
typedef string TreeItemType;

class TreeNode { 			// node in the tree
private:
	TreeNode();
	TreeNode(const TreeItemType& nodeItem, int left, int right);


	TreeItemType item; 		// data portion
	int leftChild; 			// index to left child
	int rightChild; 		// index to right child

	// friend class - can access private parts
	friend class BinaryTree;
};
 
// An array of tree nodes
TreeNode[MAX_NODES] tree;
int  root;
int  free;
#+end_src
**** Notes
#+call: shot()

#+RESULTS:
[[file:./pics/220222-1010-23.png]]

#+call: shot()

#+RESULTS:
[[file:./pics/220222-1010-36.png]]

- In this implementation, we keep the indices of the children
- We use a free list to keep track of the available nodes
- Free nodes are "linked" through their ~rightChild~ field to avoid moving array items during insertion/deletion
  - ~free~ variable keeps the index of the first free node
- This is an efficient-but-dirty implementation
**** For a complete binary tree
- We can predetermine fixed indices for child nodes (since a complete binary tree is always filled from left to right)

  #+call: shot()

  #+RESULTS:
  [[file:./pics/220222-1013-28.png]]

  #+call: shot()

  #+RESULTS:
  [[file:./pics/220222-1013-46.png]]

- For the nth node of the complete binary tree
  - $2n + 1$ gives the left child
  - $2n + 2$ gives the right child
  - $(n-1) / 2$ gives the parent
    - Note that this is integer division

- If the index of a child is > node count, the child does not exist

**** Pointer-Based Implementation
- More intuitive
- Doesn't need bookkeeping for free slots
- Need to be careful w/ memory management
***** Implementation of a binary tree node
***** TreeNode.h
#+begin_src cpp
typedef string TreeItemType;

class TreeNode {            // node in the tree
private:
    TreeNode() {}
    TreeNode(const TreeItemType& nodeItem,
        TreeNode *left = NULL,
        TreeNode *right = NULL)
        :item(nodeItem),leftChildPtr(left),rightChildPtr(right) {}

    TreeItemType item;       // data portion
    TreeNode *leftChildPtr;  // pointer to left child
    TreeNode *rightChildPtr; // pointer to right child

    friend class BinaryTree;
};
#+end_src
***** TreeException.h
#+begin_src cpp
class TreeException : public exception{

private:
    string msg;

public:
	virtual const char* what() const throw()
	{
		return msg.c_str();
	}
   TreeException(const string & message =""):
	exception(), msg(message) {};
	~TreeException() throw() {};

}; // end TreeException
#+end_src

**** The BinaryTree Class
- Most methods are straightforward
- Here are some more interesting examples
***** Constructors
#+begin_src cpp
BinaryTree::BinaryTree() : root(NULL) {}

// For internal usage: directly take the node ptr as root
BinaryTree::BinaryTree(TreeNode *node) : root(node) {}

// Construct a tree with a root node
BinaryTree::BinaryTree(const ItemType& rootItem) {
    root = new TreeNode(rootItem, NULL, NULL);
}

// Construct a binary tree w/ a root node and 2 subtrees
BinaryTree::BinaryTree(const ItemType& rootItem, BinaryTree& left, BinaryTree& right) {
    root = new TreeNode(rootItem, NULL, NULL);
    attachLeftSubtree(left);
    attachRightSubtree(right);
}
#+end_src
***** Attaching subtrees
- Check the invariants for a binary tree
  1. The tree shall not be empty
  2. There shall not be an existing child
#+begin_src cpp
void BinaryTree::attachLeftSubtree(BinaryTree& left) {
    // Check invariant
    if (!isEmpty() && root->leftChildPtr == NULL) {
        root->leftChildPtr = leftTree.root;
        // Design decision: we empty the tree passed in the parameter
        leftTree.root = NULL;
    }
    // TODO notify caller (via exceptions, return param etc.) when invariants not satisfied
}
#+end_src
***** Copying the tree (Tree traversal example)
- We use preorder traversal (visit node first, then children)
- Example of a recursive operation on a tree
#+begin_src cpp
// Copy constructor
BinaryTree::BinaryTree(const BinaryTree& tree) {
		copyTree(tree.root, root);
}


// Uses preorder traversal for the copy operation
// (Visits first the node and then the left and right children)
void BinaryTree::copyTree(TreeNode *treePtr, TreeNode *& newTreePtr) const {

		if (treePtr != NULL) {		// copy node
			newTreePtr = new TreeNode(treePtr->item, NULL, NULL);
			copyTree(treePtr->leftChildPtr, newTreePtr->leftChildPtr);
			copyTree(treePtr->rightChildPtr, newTreePtr->rightChildPtr);
		}
		else
			newTreePtr = NULL;	// copy empty tree
}

#+end_src
***** Deleting a tree (Tree traversal example)
- We use postorder traversal (because the root cannot be deleted before its children)
  - Otherwise we lose the ptrs for the children --> *Memory Leak*
#+begin_src cpp
// Destructor
BinaryTree::~BinaryTree() {
		destroyTree(root);
}


// Uses postorder traversal for the destroy operation
// (Visits first the left and right children and then the node)
void BinaryTree::destroyTree(TreeNode *& treePtr) {

		if (treePtr != NULL){
			destroyTree(treePtr->leftChildPtr);
			destroyTree(treePtr->rightChildPtr);
			delete treePtr;
			treePtr = NULL;
		}
}
#+end_src
***** Tree Traversal Methods (Function Pointers)
- These methods apply a given function to each node of the tree
- They differ in their order of traversal (see Tree Traversal Types)
****** Function pointers
- Points to the address of a given function
- Example:
  #+begin_src cpp
typedef int TreeItemType;
typedef void (*FunctionType)(TreeItemType& anItem);

void apply(TreeItemType* arr, int count, FunctionType fcn) {
    for (int i = 0; i < count; i++) {
        fcn(arr[i]);
    }
}

void display(TreeItemType& i) {
    std::cout << i << std::endl;
}
int main(void) {

    TreeItemType* arr = {1,2,3,4,5,7};
    int count = 6;

    apply(arr, count, display);
    return 0;
}
  #+end_src
****** Implementation
#+begin_src cpp
public:
void BinaryTree::preorderTraverse(FunctionType visit) {
    preorder(root, visit);
}
void BinaryTree::inorderTraverse(FunctionType visit) {
    inorder(root, visit);
}
void BinaryTree::postorderTraverse(FunctionType visit) {
    postorder(root, visit);
}
private:
/* Apply function on the node first, then traverse children */
void BinaryTree::preorder(TreeNode* node, FunctionType fcn) {
    if (node == NULL) return;
    fcn(node->item);
    preorder(node->leftChildPtr, fcn);
    preorder(node->rightChildPtr, fcn);
}

// Apply function to left, node, right
void BinaryTree::inorder(TreeNode* node, FunctionType fcn) {
    if (node) {
        inorder(node->leftChildPtr, fcn);
        fcn(node->item);
        inorder(node->rightChildPtr, fcn);
    }
}

// Apply function on children first
void BinaryTree::postorder(TreeNode* node, FunctionType fcn) {
    if (node) {
        postorder(node->leftChildPtr, fcn);
        postorder(node->rightChildPtr, fcn);
        fcn(node->item);
    }
}
#+end_src
****** Complexity
 - If number of nodes = n, the traversal takes $O(n)$ time for all 3
** Binary Search Trees
- A binary tree where every node satisfies the following:
  1. All values in left subtree are smaller than the value in the node
  2. All values in right subtree are larger than the value in the node
  3. The subtrees are also BSTs
- Note that BSTs can be unbalanced
    #+call: shot()

    #+RESULTS:
    [[file:./pics/220224-1443-11.png]]
    #+call:shot()

    #+RESULTS:
    [[file:./pics/220224-1443-26.png]]

  - Makes searching less efficient
*** TreeNode class
#+begin_src cpp
class TreeNode { 	// a node in the tree
private:
		TreeNode() { }
		TreeNode(const TreeItemType& nodeItem,TreeNode *left = NULL,
							     TreeNode *right = NULL)
		: item(nodeItem), leftChildPtr(left), rightChildPtr(right){ }


		TreeItemType item; 		// a data item in the tree
		TreeNode *leftChildPtr;	// pointers to children
		TreeNode *rightChildPtr;


	// friend class - can access private parts
	friend class BinarySearchTree;
};
#+end_src
*** Searching an item in a BST
- Start at the root, then proceed to the children
  - If data in node > query, proceed to left
  - If data in node < query, proceed to right
  - If data in node == query, search is successful
#+begin_src cpp
public:
void BinarySearchTree::search(int key, TreeItemType& item) {
    retrieveItem(root, key, item);
}
private:
void BinarySearchTree::retrieveItem(TreeNode*& node, int key, TreeItemType& item) {
    if (!node) {
        item = NULL;
    } else if (key == node->item.getKey()) {
        item = node->item;
    } else if (key < node->item.getKey()) {
        retrieveItem(node->leftChildPtr, key, item);
    } else {
        retrieveItem(node->rightChildPtr, key, item);
    }
}
#+end_src
*** Insertion in a BST
- The location must satisfy the BST invariants (see definition of BST)
- The insertion point is determined via a search
#+begin_src cpp
public:
void BinarySearchTree::insert(const TreeItemType& item) {
    insertItem(root, item);
}

private:
// Assume items are unique
void BinarySearchTree::insertItem(TreeNode*& node, const TreeItemType& item) {
    if (!node) // found appropriate position
        node = new TreeNode(item, NULL, NULL);
    else if (item < node->item)
        insertItem(node->leftChildPtr, item);
    else
        insertItem(node->rightChildPtr, item);
}
#+end_src
*** Deleting a BST node
- Three possible cases:
  1. A leaf node: Delete the node
  2. A node with one child: Connect the node's child to the node's parent, then delete
  3. A node with two children: Complicated
**** Deleting a node with two children
- Find a successor for the node to be deleted
  - Successor :: The smallest node (within the subtrees of a node) that is greater than the node
- Find the leftmost node in the right subtree
- Move the data in the successor to the node to be deleted
- Delete the successor (which is easy to delete)
**** C++ implementation
#+begin_src cpp
void BinarySearchTree::findSuccessor(TreeNode *&node, int& replacement);

void BinarySearchTree::deleteNode(TreeNode *&node) {
    TreeNode *del;
    int replacement;

    // Leaf node
    if (!(nodePtr->leftChild) && !nodePtr->rightChild) {
        delete node;
        node = NULL;
    } else if (!nodePtr->rightChild) { // Only left child
        del = node;
        node = node->leftChild;
        del->leftChild = NULL;
        delete del;
    } else if (!nodePtr->leftChild) { // Only right child
        del = node
        node = node->rightChild;
        del->rightChild = NULL;
        delete del;
    } else { // Two children
        findSuccessor(node->rightChild, replacement);
        node->item = replacement;
    }
}

void BinarySearchTree::findSuccessor(TreeNode *&node, int& replacement){

    if (node->leftChild) { // Not NULL
         findSuccessor(node->leftChild, replacement);
    } else {
        TreeNode successor = node;
        replacement = successor->item;
        node = node->rightChild;
        successor->rightChild = NULL;
        delete successor;
    }
}

#+end_src
**** Analysis
- Time complexity: $O(h)$ where h = height of the bin. tree
*** Traversals
- Theorem :: Inorder traversal of a binary search tree will visit its nodes in sorted order.
- Proof :: We use proof by induction.
  - Basis :: $h = 0 \implies$ no nodes visited, the empty list is sorted.
  - Inductive Hypothesis :: Assume the theorem holds for $0 \le k < h$.
  - Proof :: Let r be the value in the root node of a BST of height h+1, $T_L$ and $T_R$ be the left and right children of the root respectively.
    Since the height of the children are < h, the theorem holds for $T_L$ and $T_L$.
    By the definition of a BST, all nodes in $T_L$ are < r and all nodes in $T_R$ are > r.
    Since inorder traversal visits $T_L$, $r$, $T_R$ in the given order, the inorder traversal of a tree with height h+1 yields a sorted list.
    Therefore the theorem holds for height h+1 if the theorem is true for heights < h.
*** Minimum height of a BST
- Complete and full BSTs have minimum height
- The height of a BST with n nodes varies from $\lceil \log_2{(n+1)} \rceil$ to $n$.
- Insertion in sorted order produces a maximum height BST.
- Insertion in random order produces a near minimum height BST.
*** How many BSTs are possible for a given set of items?
- There are $n!$ orderings possible for n unique keys
- How many BSTs are possible for n items?
  - $n = 0 \implies 1$
  - $n = 1 \implies 1$
  - $n = 2 \implies 2$
  - $n = 3 \implies 5$
- $5 < 3! = 6$
  - By the pigeonhole principle, at least one of the tree configurations are produced by two distinct orderings
  - For n = 3 this is the balanced tree
- As n increases, the probability of getting a balanced (or near-balanced) BST increases
*** Treesort
- We can use a BST to sort a given array
  1. Insert the items into a BST
  2. Perform in-order traversal
**** Analysis
- Inserting an item into a BST
  - Worst case: $O(n)$
  - Average case: $O(\log_2{n})$
- Inserting n items into a BST
  - Worst case: $O(n^2)$
  - Average case: $O(n \log_2{n})$
- In-order traversal: $O(n)$
- Copying to the array: $O(n)$
- Therefore tree sort has avg. time complexity $O(n \log_2{n})$
  - Worst case complexity $O(n^2)$
*** Saving and restoring BSTs
**** Original shape
- Use preorder traversal to save the nodes
- Insert the nodes in the order they are saved into a BST
**** Balanced
- Use in-order traversal to save the elements in sorted order
- Then construct a balanced BST from the sorted list
***** Construct balanced BST from sorted list
- Pick the middle element as root
- Use the left half of the array to construct the left subtree recursively
- Use the right half of the array to construct the right subtree recursively

#+begin_src cpp
// Note: should be friend fcn of BSTNode
BSTNode* readTree(int n, std::istream& file) {
    BSTNode* node = NULL;
    if (n > 0) {
        node = new BSTNode; // Leaf node

        node->left = readTree(n/2, file);
        node->item << file;
        node->right = readTree((n-1)/2, file);
    }

    return node;
}
#+end_src

* Tables and Priority Queues
[[file:../slides/heaps.pptx][slideshow]]
** Tables
- array or linked list implementations are called linear since the items come one after another
  - Unsorted array
  - Unsorted linked list
  - Sorted array
  - Sorted linked list
- There are also nonlinear implementations such as BSTs
** Priority Queues
** Heaps
- A heap is a complete binary tree such that
  - It is empty
  - Its root contains a key greater than the keys in its children, and its children are also heaps
- This is known as a maxheap
#+call: shot()

#+RESULTS:
[[file:./pics/220303-1511-16.png]]
*** Differences between heap and BST
1. A BST is sorted, but a heap does not have an absolute order
2. A heap *must* be a complete binary tree, while a BST can have different shapes
*** TODO Deleting a node from a heap
*** TODO restoring the heap
*** TODO Heapsort
